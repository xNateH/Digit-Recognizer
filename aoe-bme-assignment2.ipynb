{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Nathan Haile nah2174\n","metadata":{}},{"cell_type":"markdown","source":"# Art of Engineering\n## Biomedical Engineering Departmental Project\n\n### <span style=\"color:red\">Assignment 2</span> - MNIST Classification using LeNet\n\n#### Due date/time: <span style=\"color:red\">November 4, 05:00 pm</span>\n\n#### Instructions:\n1. You may use any publicly available resources to answer the questions, but you need to ***cite*** them properly to prevent plagiarism.\n2. Using or copying other students' solutions is considered cheating, and you'll be graded **\"0\" for the entire assignment**.\n3. You may be asked to write Python code or to explain something in each question. To write your answers, please use code and markdown blocks, respectively. If you need to better organize your answers, you may add more blocks. In this notebook, we placed a code block with a comment as `# [Your code here]` and a markdown block with the text \"<span style=\"color:red\">Your answer here</span>\" for each question that needs them. If you wish to answer, please remove the comments first.\n4. Please ***use comments at the beginning of each code blocks*** to explain what you've implemented in that block.\n5. Please ***use LaTex formatting to write equations and formulas*** in markdown blocks wherever is needed.\n6. Please define your variables with ***short and meaningful names***.\n7. Please make sure ***internet access is granted*** on the settings panel.\n8. For this assignment, you ***need GPU access***. Please set the \"Accelerator\" as \"GPU\" on the \"Setting\" panel.\n\n#### How to submit:\nKaggle automatically saves the notebook after few seconds, and you may close the notebook and come back later to complete it. However, we need you to do the following steps to ensure your answers are visible to us for grading purposes. Thus, after you finished your answers, please:\n1. Rename the notebook as \"AoE_BME_Assignment2\".\n2. Click on the \"Save Version\" button on the top-right side of the window.\n3. On the save popup, save your notebook with: \\\n    3.1 If the scripts run fast, the \"Save & Run All (Commit)\" option, \\\n    3.2 If the scripts run slow, such as training networks, etc., and you are satisfied with the outputs of code blocks, \"Quick Save\" option.\n4. Click on the \"Save\" button and let the Kaggle saves your notebook.\n5. Then click on the \"Share\" button.\n6. On the share popup, change \"Private\" to \"Public\".\n7. Copy the \"Public url\", and click on the \"Save\" button.\n8. Paste the \"Public url\" address on the related assignment on the [CourseWorks](https://courseworks2.columbia.edu/) and submit it.\n\n**Note:**\n1. You may save multiple versions of your notebook, but the latest version is considered as your final answer.\n2. If you wish us to grade your answers based on a different version of your notebook other than the latest version, please duplicate this template, copy your answers from your desired version, and follow the same procedure to submit. Again, make sure the name of the notebook remains as the current template.\n3. Do not change or save the notebook after the due date/time as it will be considered a late submission and causes a decrease in your final grade.","metadata":{}},{"cell_type":"markdown","source":"#### <span style=\"color:red\">(0 pts.) Q0. </span> \n#### a. Import the packages you need similar to the notebook of the Lecture 3 - Part C. \n#### b. Check if the GPU is available.\n#### c. Set the random seed for both Pytorch and Numpy as 1102","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nfrom torch.utils.data import TensorDataset, DataLoader\n\nimport tensorflow.keras.datasets.mnist as MNIST\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport warnings\n\ncuda = torch.cuda.is_available()\nprint(\"GPU available:\", cuda)\n\ntorch.manual_seed(1102)\nnp.random.seed(1102)\n\n#References: https://www.kaggle.com/code/snnaik/aoe-bme-lecture3-partc-mlp-lenetformnist","metadata":{"execution":{"iopub.status.busy":"2023-09-14T06:49:08.139276Z","iopub.execute_input":"2023-09-14T06:49:08.139720Z","iopub.status.idle":"2023-09-14T06:49:08.150906Z","shell.execute_reply.started":"2023-09-14T06:49:08.139679Z","shell.execute_reply":"2023-09-14T06:49:08.149484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <span style=\"color:red\">(5 pts.) Q1. </span> \n#### a. Download the MNIST dataset using MNIST package. (Make sure the images and labels for both training set and test set are downloaded correctly)\n#### b. Using `train_test_split` function, split training set into a new training set and validation set by a ratio of 20%.\n#### c. Print the number of samples, minimum and maximum intensity, and the shape of the images matrix for all three sets.","metadata":{}},{"cell_type":"code","source":"(trainingSET, label_train), (testing, label_test) = MNIST.load_data()\n\n#split the training set into new training set and validation set\ntrainingSET, validation, label_train, label_val = train_test_split(trainingSET, label_train, test_size=0.2)\n\n#print num entries, max and min value, shape\nprint(trainingSET.shape[0], np.max(trainingSET), np.min(trainingSET), trainingSET.shape)\nprint(validation.shape[0], np.max(validation), np.min(validation), validation.shape)\nprint(testing.shape[0], np.max(testing), np.min(testing), testing.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T06:49:08.153177Z","iopub.execute_input":"2023-09-14T06:49:08.153873Z","iopub.status.idle":"2023-09-14T06:49:08.590415Z","shell.execute_reply.started":"2023-09-14T06:49:08.153829Z","shell.execute_reply":"2023-09-14T06:49:08.589430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"#### <span style=\"color:red\">(5 pts.) Q2. </span> Display 24 first samples pulled from each set (train, validation, and test) and show the true labels as the title per each sample. \n**Note:** Display all 24 samples pulled from each set in one plot as in four rows and six columns. Thus, we will expect three plots for training, validation, and test set.","metadata":{}},{"cell_type":"code","source":"sets = [trainingSET, trainingSET, trainingSET]\nlabels = [label_train, label_val, label_test]\ntitles = ['Training ', 'Validation', 'Testing']\nfor s in range(len(sets)): \n    row = 4\n    col = 6\n    fig = plt.figure(figsize = (12, 15))\n    \n    plt.suptitle(f\"From {titles[s]}\")\n    for i in range(1, row * col + 1):\n        \n        IMG = sets[s][i, :, :]\n        val = fig.add_subplot(row, col, i)\n        val.set_xticks([])\n        val.set_yticks([])\n        val.title.set_text(str(labels[s][i]))\n        plt.imshow(IMG, cmap = 'gray')\n        \n    plt.show()\n    print\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T06:49:08.591886Z","iopub.execute_input":"2023-09-14T06:49:08.592490Z","iopub.status.idle":"2023-09-14T06:49:12.043292Z","shell.execute_reply.started":"2023-09-14T06:49:08.592444Z","shell.execute_reply":"2023-09-14T06:49:12.042334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <span style=\"color:red\">(8 pts.) Q3. </span> \n#### a. Similar to the lecture, reformat all samples and create a `DataLoader` of batch size 100 for each set. \n#### b. Print the total number of batches in each `DataLoader`. (You can use `len()` function on `DataLoader`)\n**Note:** Do not forget to add one axis for channels. The Pytorch's tensor format is (BatchSize, Channel, Width, Height).","metadata":{}},{"cell_type":"code","source":"# [your code here]\nimage_train_torch = torch.from_numpy(trainingSET).type(torch.FloatTensor).view(-1, 1, 28, 28)\nlabel_train_torch = torch.from_numpy(label_train).type(torch.LongTensor)\n\nimage_validation_torch = torch.from_numpy(validation).type(torch.FloatTensor).view(-1, 1, 28, 28)\nlabel_validation_torch = torch.from_numpy(label_val).type(torch.LongTensor)\n\nimage_test_torch = torch.from_numpy(testing).type(torch.FloatTensor).view(-1, 1, 28, 28)\nlabel_test_torch = torch.from_numpy(label_test).type(torch.LongTensor)\n\ntrain_data = TensorDataset(image_train_torch, label_train_torch)\ntrain_loader = DataLoader(train_data, batch_size = 100)\n\nprint(len(train_loader))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T06:49:12.044892Z","iopub.execute_input":"2023-09-14T06:49:12.045513Z","iopub.status.idle":"2023-09-14T06:49:12.201598Z","shell.execute_reply.started":"2023-09-14T06:49:12.045467Z","shell.execute_reply":"2023-09-14T06:49:12.200481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <span style=\"color:red\">(12 pts.) Q4. </span> Using the lecture's notebook on LeNet, define a model as the following table:\n| Layer Number | Layer Type   | Number of kernels | Kernel size | Activation | Stride | Zero-Padding |\n| ------------ | ------------ | ----------------- | ----------- | ---------- | ------ | ------------ |\n| 1            | Conv2D       | 32                | 5x5         | ReLU       | 1      | 0            |\n| 2            | MaxPooling2D | NA                | 2x2         | NA         | 2      | 0            |\n| 3            | Conv2D       | 64                | 3x3         | ReLU       | 1      | 0            |\n| 4            | MaxPooling2D | NA                | 2x2         | NA         | 2      | 0            |\n| 5            | Conv2D       | 128               | 2x2         | ReLU       | 1      | 0            |\n| 6            | MaxPooling2D | NA                | 2x2         | NA         | 2      | 0            |\n| 7            | Faltten      | NA                | NA          | NA         | NA     | NA           |\n| 8            | FC (Linear)  | 128               | NA          | ReLU       | NA     | NA           |\n| 9            | FC (Linear)  | 64                | NA          | Sigmoid    | NA     | NA           |\n| 10           | FC (Linear)  | 10                | NA          | SoftMax    | NA     | NA           |\n**Note:** **NA** means not applicable.\n\n#### Then create an instance of the model and load it on the GPU by calling the `.cuda()` function.","metadata":{}},{"cell_type":"code","source":"# Formula to calculate shape as we go through layer by layer = [(X - F + 2P)/S] + 1\n# Here,\n# X = Width / Height\n# F = Kernel size\n# P = Padding\n# S = Strides (default = 1)\n\n# Our input to the first layer is going to be [batchsize, 1, 32, 32]\n# substitute, =[(28 - 5 + 2(0))/1] + 1\n#             =[(23)/1] + 1\n#             =23 + 1\n#             =24\n\n\nclass MLPModel(nn.Module):\n    '''Reshape -> FC -> Sigmoid -> FC -> Sigmoid -> FC -> SoftMax -> Cross-Entropy'''\n    def __init__(self):\n        '''Define model modules.'''\n        super(MLPModel, self).__init__()\n        self.fc1 = nn.Linear(28 * 28, 128)\n        self.fc2 = nn.Linear(128, 64)\n        self.fc3 = nn.Linear(64, 10)\n\n    def forward(self, x):\n        '''Define the model architecture (the sequence to place the model modules).'''\n        x = x.view(-1, 28 * 28)\n        x = self.fc1(x)\n        x = F.sigmoid(x)\n        x = self.fc2(x)\n        x = F.sigmoid(x)\n        x = self.fc3(x)\n        return F.log_softmax(x, dim = 1)\n\nour_MLP = MLPModel()\n\n# If GPU available, move the model to GPU.\nif cuda:\n    our_MLP.cuda()\n\nprint(our_MLP)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T06:49:12.206753Z","iopub.execute_input":"2023-09-14T06:49:12.207303Z","iopub.status.idle":"2023-09-14T06:49:12.221558Z","shell.execute_reply.started":"2023-09-14T06:49:12.207263Z","shell.execute_reply":"2023-09-14T06:49:12.220778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <span style=\"color:red\">(10 pts.) Q5. </span> Knowing the input shape of each image in the MNIST dataset is $28\\times28$, write the shape of the output tensor for each layer of the model.\n**Note:** You can use the following formula: \\\nAssuming the input shape is: $(B, Ch_{in}, W_{in}, H_{in})$, and the output shape is $(B, Ch_{out}, W_{out}, H_{out})$ \\\n1. For the `Conv2D` layers with $N$ number of $K\\times K$ kernels, zero-padding $P$, and stride $S$:\n$$\nW_{out} \\text{ or } H_{out} = \\lfloor {\\frac{W_{in} \\text{ or } H_{in} + 2P - K }{S}} + 1 \\rfloor\n$$\n$\\lfloor . \\rfloor$ means integer floor.\n\nAnd the number of channels for the output will be $Ch_{out} = N$\n\n2. Similarly for the `Maxpooling` layers of size $K \\times K$, zero-padding $P$, and stride $S$:\n$$\nW_{out} \\text{ or } H_{out} = \\lfloor {\\frac{W_{in} \\text{ or } H_{in} + 2P - K }{S}} + 1 \\rfloor\n$$\n\nThe only difference is that the number of channels for the output will be $Ch_{out} = Ch_{in}$\n\n3. For `Linear` (Also known as Fully-Connected) layers, the input is a vector of $(B, D_{in})$. Assuming the layer has $N$ number of neurons, the output is a vector of size $(B, N)$.\n\n**Note:** $B$ stands for the batch size.","metadata":{}},{"cell_type":"markdown","source":"\nLayer 1: W = [(28 - 5 + 2*0)/1] + 1 = 24, 32 Channels\n\nLayer 2: W = [(24 - 2 + 2*0)/2] + 1 = 12, 32 Channels\n\nLayer 3: W = [(12 - 3 + 2*0)/1] + 1 = 10, 64 Channels\n\nLayer 4: W = [(10 - 2 + 2*0)/2] + 1 = 5, 64 Channels\n\nLayer 5: W = [(5 - 2 + 2*0)/1] + 1 = 4, 128 Channels\n\nLayer 6: W = [(4 - 2 + 2*0)/2] + 1 = 2, 128 Channels\n\nLayer 7: D = 512 *Reshape*\n\nLayer 8: Vector: <100, 128>\n\nLayer 9: Vector: <100, 64>\n\nLayer 10: Vector: <100, 10>","metadata":{}},{"cell_type":"markdown","source":"#### <span style=\"color:red\">(5 pts.) Q6. </span> Define an SGD optimizer with a learning rate of $10^{-3}$ on the parameters of the model.","metadata":{}},{"cell_type":"code","source":"# define our optimizer\noptimizer = SGD(our_MLP.parameters(), lr = 0.001)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T06:49:12.223462Z","iopub.execute_input":"2023-09-14T06:49:12.223966Z","iopub.status.idle":"2023-09-14T06:49:12.229101Z","shell.execute_reply.started":"2023-09-14T06:49:12.223923Z","shell.execute_reply":"2023-09-14T06:49:12.228063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <span style=\"color:red\">(25 pts.) Q7. </span> Similar to the example on LeNet, train your network on a train set for 50 epochs. Use the \"Cross-Entropy\" (`F.cross_entropy`) as the loss function. \n#### At the end of each epoch, save the model, test the model on the validation set, and keep the training and validation loss for later. \n**Note:** Remember that the loss is calculated for each batch; thus, you need to take the average loss over all batches as the epoch loss for both training and validation phases.","metadata":{}},{"cell_type":"code","source":"!mkdir saved_models_MLP","metadata":{"execution":{"iopub.status.busy":"2023-09-14T06:49:12.230819Z","iopub.execute_input":"2023-09-14T06:49:12.231259Z","iopub.status.idle":"2023-09-14T06:49:13.269721Z","shell.execute_reply.started":"2023-09-14T06:49:12.231223Z","shell.execute_reply":"2023-09-14T06:49:13.268455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 50\n\ntrain_epoch_loss = []\nvalidation_epoch_loss = []\n\nfor epoch in range(EPOCHS):\n    train_loss = []\n    validation_loss = []\n\n    for batch_index, (train_image, train_label) in enumerate(train_loader):\n        # If GPU is available, move the data to the GPU for faster computation.\n        if cuda:\n            #######################################################\n            ####################### Train #########################\n            #######################################################\n            # Set the model to train mode so that the parameters can be updated.\n            our_MLP.train()\n\n            train_label_predicted = our_MLP(train_image.cuda())\n\n            # compute the loss\n            loss = F.cross_entropy(train_label_predicted, train_label.cuda())\n            train_loss.append(loss.cpu().data.item())\n\n            # reset the gradient \n            optimizer.zero_grad()\n            # backpropagate the loss\n            loss.backward()\n            # update the parameters\n            optimizer.step()\n\n            #######################################################\n            ###################### Validation #####################\n            #######################################################\n            # Set the model to evaluation mode so that parameters are fixed.\n            our_MLP.eval()\n\n            validation_label_predicted = our_MLP(image_validation_torch.cuda())\n\n            loss = F.cross_entropy(validation_label_predicted, label_validation_torch.cuda())\n            validation_loss.append(loss.cpu().data.item())\n        \n        # If GPU is not available.\n        else:\n            #######################################################\n            ####################### Train #########################\n            #######################################################\n            # Set the model to train mode so that the parameters can be updated.\n            our_MLP.train()\n\n            train_label_predicted = our_MLP(train_image)\n\n            # compute the loss\n            loss = F.cross_entropy(train_label_predicted, train_label)\n            train_loss.append(loss.cpu().data.item())\n\n            # reset the gradient\n            optimizer.zero_grad()\n            # backpropagate the loss\n            loss.backward()\n            # update the parameters\n            optimizer.step()\n\n            #######################################################\n            ###################### Validation #####################\n            #######################################################\n            # Set the model to evaluation mode so that parameters are fixed.\n            our_MLP.eval()\n\n            validation_label_predicted = our_MLP(image_validation_torch)\n\n            loss = F.cross_entropy(validation_label_predicted, label_validation_torch)\n            validation_loss.append(loss.cpu().data.item())\n\n    train_epoch_loss.append(np.mean(train_loss))\n    validation_epoch_loss.append(np.mean(validation_loss))\n    \n    # save models\n    torch.save(our_MLP.state_dict(), './saved_models_MLP/checkpoint_epoch_%s.pth' % (epoch))\n\n    print(\"Epoch: {} | train_loss: {} | validation_loss: {}\".format(epoch, train_epoch_loss[-1], validation_epoch_loss[-1]))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T06:49:13.271723Z","iopub.execute_input":"2023-09-14T06:49:13.272168Z","iopub.status.idle":"2023-09-14T06:53:55.210163Z","shell.execute_reply.started":"2023-09-14T06:49:13.272125Z","shell.execute_reply":"2023-09-14T06:53:55.209161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <span style=\"color:red\">(5 pts.) Q8. </span> Plot the learning curve and indicate in which epoch the model achieved the lowest validation loss.\n**Note:** The learning curve is a plot that shows the training and validation loss for each epoch.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (12, 8))\nplt.plot(train_epoch_loss, '-o', label = 'training loss', markersize = 3)\nplt.plot(validation_epoch_loss, '-o', label = 'validation loss', markersize = 3)\nplt.legend(loc = 'upper right');\n\n\nbest_epoch = np.argmin(validation_epoch_loss)\nprint('best epoch: ', best_epoch)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T06:53:55.211492Z","iopub.execute_input":"2023-09-14T06:53:55.211862Z","iopub.status.idle":"2023-09-14T06:53:55.431702Z","shell.execute_reply.started":"2023-09-14T06:53:55.211818Z","shell.execute_reply":"2023-09-14T06:53:55.430082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <span style=\"color:red\">(20 pts.) Q9. </span> \n#### a. Load the weights of the best epoch and test the model on the test set.\n#### b. Test the model on the first sample of the test set and plot the output probabilities.\n#### c. Print the overall accuracy of the model on the test set. Accuracy formula is $Accuracy=\\frac{\\text{Number of correct prediction}}{\\text{Total Number of samples}}$\n#### d. Plot the confusion matrix for the test set.\n\n**Note:** The testing phase is similar to the validation phase. You need to loop through batches of the test loader and keep the true labels and predicted labels for accuracy and confusion matrix.","metadata":{}},{"cell_type":"code","source":"state_dict = torch.load('./saved_models_MLP/checkpoint_epoch_%s.pth' % (epoch))\nprint(state_dict.keys())\nour_MLP.load_state_dict(state_dict)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T06:53:55.433055Z","iopub.execute_input":"2023-09-14T06:53:55.433431Z","iopub.status.idle":"2023-09-14T06:53:55.446247Z","shell.execute_reply.started":"2023-09-14T06:53:55.433393Z","shell.execute_reply":"2023-09-14T06:53:55.445114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_with_pytorch(model, input_data):\n    model.eval()\n    label_predicted_all = []\n\n    label_predicted_one_hot = model(input_data)\n    label_predicted_probability, label_predicted_index = torch.max(label_predicted_one_hot.data, 1)\n    \n    for current_prediction in label_predicted_index:\n        label_predicted_all.append(current_prediction.detach().cpu().numpy().item())\n\n    return label_predicted_all\n\nif cuda:\n    test_label_predicted = predict_with_pytorch(our_MLP, image_test_torch.cuda())\nelse:\n    test_label_predicted = predict_with_pytorch(our_MLP, image_test_torch)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T06:53:55.448667Z","iopub.execute_input":"2023-09-14T06:53:55.448939Z","iopub.status.idle":"2023-09-14T06:53:55.659611Z","shell.execute_reply.started":"2023-09-14T06:53:55.448912Z","shell.execute_reply":"2023-09-14T06:53:55.658716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def view_classify(image, probabilities, version = \"MNIST\"):\n    ''' Function for viewing an image and it's predicted classes.\n    '''\n    probabilities = probabilities.data.numpy().squeeze()\n\n    fig, (ax1, ax2) = plt.subplots(figsize = (6, 9), ncols = 2)\n    ax1.imshow(image.resize_(1, 28, 28).numpy().squeeze(), cmap = 'gray')\n    ax1.set_title('Original Image')\n    ax1.axis('off')\n    ax2.bar(np.arange(10), probabilities)\n    ax2.set_aspect(10)\n    ax2.set_xticks(np.arange(10))\n        \n    ax2.set_title('Class Probability')\n    ax2.set_ylim(0, 1.1)\n\n    plt.tight_layout()\n   \nour_MLP.eval()\n\nsample_test_image = image_test_torch[0, :, :, :][np.newaxis, :, :, :]\n\nif cuda:\n    sample_prediction = our_MLP(sample_test_image.cuda())\nelse:\n    sample_prediction = our_MLP(sample_test_image)\n    \nwarnings.filterwarnings('ignore')\n\nif cuda:\n    view_classify(sample_test_image, 2 ** sample_prediction.cpu())\nelse:\n    view_classify(sample_test_image, 2 ** sample_prediction)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-14T06:53:55.661241Z","iopub.execute_input":"2023-09-14T06:53:55.661749Z","iopub.status.idle":"2023-09-14T06:53:55.919100Z","shell.execute_reply.started":"2023-09-14T06:53:55.661705Z","shell.execute_reply":"2023-09-14T06:53:55.918048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"j=0\nmatch = 0\n\nfor i in test_label_predicted:\n    if i== label_test[j]:\n        match = match + 1\n    j = j+1\n    \n    \nprint(\"Accuracy:\", round((match/len(label_test) * 100),2) , \"%\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T06:53:55.920454Z","iopub.execute_input":"2023-09-14T06:53:55.920840Z","iopub.status.idle":"2023-09-14T06:53:55.960593Z","shell.execute_reply.started":"2023-09-14T06:53:55.920801Z","shell.execute_reply":"2023-09-14T06:53:55.959711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CM = confusion_matrix(label_test, test_label_predicted)\n\nplt.figure(figsize = (12,10))\nsns.heatmap(CM, annot = True, annot_kws = {\"size\": 10})\nplt.ylim([0, 10]);\nplt.ylabel('True labels');\nplt.xlabel('predicted labels');","metadata":{"execution":{"iopub.status.busy":"2023-09-14T06:53:55.961994Z","iopub.execute_input":"2023-09-14T06:53:55.962391Z","iopub.status.idle":"2023-09-14T06:53:56.968054Z","shell.execute_reply.started":"2023-09-14T06:53:55.962353Z","shell.execute_reply":"2023-09-14T06:53:56.967011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <span style=\"color:red\">(5 pts.) Q10. </span> Compare the performance of your architecture with the LeNet performance. Which one performs better on the MNIST classification? Can you suggest any method to improve either of the models?","metadata":{}},{"cell_type":"markdown","source":"My model performed better on the MNIST classification compared to the LeNet model. I would presume a larger network of more layers would raise accuracy.\nTo improve the accuracy of either model, I would suggest using a bigger set of data/sources. Also, I would calculate the batch size and the optimal learning rate.","metadata":{}}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}